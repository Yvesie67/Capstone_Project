{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Capstone_Template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsDrM8l-04op"
      },
      "source": [
        "# Objective\n",
        "What is the objective or goal that you are trying to accomplish? What is the decision that you must make?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_uweMbZxV4c"
      },
      "source": [
        "#####In order to keep up with the needs of the market and the requirements that hold our young academics and professionals are in search of information and guidance as it becomes increasingly difficult to access the labor market. In addition to the evolution of technology and the different problems that young people face, the process of offers and recruitments are modified, of these modifications they must make choices.\n",
        "#####To address these obstacles, this analysis was conducted on job offers and job titles of the last few years.\n",
        "\n",
        "\n",
        "#####*   The goal is to guide our young academics and professionals in their choice of higher education to succeed in the job market.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fv7ykXU0_I5"
      },
      "source": [
        "# Hypothesis: Research Question?\n",
        " What is the question that you would like to answer in order to make a decision?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PNYCn48txnh"
      },
      "source": [
        "\n",
        "#####*   Are job offers enough to guide our young people or must we also take into account the evolution of the job market?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pBreNBF1FgG"
      },
      "source": [
        "# Data Source\n",
        "Explain where did you get the data. How can you trust this data? Who produced this data and what were their motiviations?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DadN_ckylRY"
      },
      "source": [
        "#####The data with which we are going to make the analysis come from the platform of Jobpaw, obtained by means of web scraping. We have information on job titles, specialties, fields and also the institutions involved. Being a research and reference site its data is quite reliable to the extent of my research project. Produced with the intention of allowing companies to have access to the job market and students, graduates and those with a PhD to have access to the job market."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNFnyfmWDon4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdBQ_GkJ1xX0"
      },
      "source": [
        "# Data Cleaning\n",
        "In this step you will prepare your data for analysis.\n",
        "\n",
        "## Review data types\n",
        "Inspect the dataset for the data types of each column.\n",
        "\n",
        "## Analytical Transformations\n",
        "Perform any transformation on the columns in the dataset to enable further analysis.\n",
        "\n",
        "### Treatment of Missing Values\n",
        "If there are any missing values, how do you plan to treat those data columns?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8R6MSjQ0AFp"
      },
      "source": [
        "#import spacy\n",
        "#import fr_core_news_md\n",
        "\n",
        "#nlp = fr_core_news_md.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8wMQh8WBtd9",
        "outputId": "c3b087b7-ddcb-4353-c23d-5f30147cae2b"
      },
      "source": [
        "!pip install dateparser\n",
        "!pip install spacy\n",
        "!python3 -m spacy download fr_core_news_md\n",
        "!python3 -m spacy download en_core_web_sm\n",
        "!pip install nltk\n",
        "!pip install langdetect\n",
        "!pip install bar_chart_race"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dateparser\n",
            "  Downloading dateparser-1.0.0-py2.py3-none-any.whl (279 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30 kB 35.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40 kB 39.0 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 51 kB 39.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 61 kB 41.9 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 71 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 81 kB 31.4 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 92 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 102 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 112 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 122 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 133 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 143 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 153 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 163 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 174 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 184 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 194 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 204 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 215 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 225 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 235 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 245 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 256 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 266 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 276 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 279 kB 28.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser) (2018.9)\n",
            "Requirement already satisfied: regex!=2019.02.19 in /usr/local/lib/python3.7/dist-packages (from dateparser) (2019.12.20)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->dateparser) (1.15.0)\n",
            "Installing collected packages: dateparser\n",
            "Successfully installed dateparser-1.0.0\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Collecting fr_core_news_md==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-2.2.5/fr_core_news_md-2.2.5.tar.gz (88.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 88.6 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from fr_core_news_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (4.62.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_md==2.2.5) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_md==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_md==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (2.10)\n",
            "Building wheels for collected packages: fr-core-news-md\n",
            "  Building wheel for fr-core-news-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-md: filename=fr_core_news_md-2.2.5-py3-none-any.whl size=90338488 sha256=b6663bf06920ed405aa1b7f0bf6838408ef77f2364c89d68dbfd4012d9643cd7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ekkqw9ze/wheels/2e/26/ff/ce93eb966e7176ebe81e6c98209582e13e108cdd2d6d636df0\n",
            "Successfully built fr-core-news-md\n",
            "Installing collected packages: fr-core-news-md\n",
            "Successfully installed fr-core-news-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_md')\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 50.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 28.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=7c6c067009b5eed8d4b89f0bccacd67c563b833eeb2bfd4657b2c516708d4d61\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n",
            "Collecting bar_chart_race\n",
            "  Downloading bar_chart_race-0.1.0-py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 35.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.1 in /usr/local/lib/python3.7/dist-packages (from bar_chart_race) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from bar_chart_race) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1->bar_chart_race) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1->bar_chart_race) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1->bar_chart_race) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1->bar_chart_race) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1->bar_chart_race) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.1->bar_chart_race) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->bar_chart_race) (2018.9)\n",
            "Installing collected packages: bar-chart-race\n",
            "Successfully installed bar-chart-race-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itu9e9OEgzXo",
        "outputId": "b608e9e9-cf3a-42b2-ee59-2b28e9941cb1"
      },
      "source": [
        "!pip install unidecode\n",
        "!pip install pycontractions\n",
        "!pip install word2number\n",
        "!pip install pycontractions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 39.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 37.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 41.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 42.8 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 42.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 42.6 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 41.6 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 41.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 42.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 42.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 42.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 42.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 42.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 42.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 42.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 42.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 42.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 42.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 42.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 42.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 42.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 42.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 42.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.2\n",
            "Collecting pycontractions\n",
            "  Downloading pycontractions-2.0.1-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: gensim>=2.0 in /usr/local/lib/python3.7/dist-packages (from pycontractions) (3.6.0)\n",
            "Collecting language-check>=1.0\n",
            "  Downloading language-check-1.1.tar.gz (33 kB)\n",
            "Requirement already satisfied: pyemd>=0.4.4 in /usr/local/lib/python3.7/dist-packages (from pycontractions) (0.5.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim>=2.0->pycontractions) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim>=2.0->pycontractions) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=2.0->pycontractions) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=2.0->pycontractions) (5.2.1)\n",
            "Building wheels for collected packages: language-check\n",
            "  Building wheel for language-check (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for language-check\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for language-check\n",
            "Failed to build language-check\n",
            "Installing collected packages: language-check, pycontractions\n",
            "    Running setup.py install for language-check ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-vwn8fo6y/language-check_90c6b779761b423d9099a1678f3567da/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-vwn8fo6y/language-check_90c6b779761b423d9099a1678f3567da/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-d_bm_l9w/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/language-check Check the logs for full command output.\u001b[0m\n",
            "Collecting word2number\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "Building wheels for collected packages: word2number\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5580 sha256=a54fe160bc4c6a28dd52175f23de258955ac3ebdd4184674d10ef97256776949\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/c3/77/a5f48aeb0d3efb7cd5ad61cbd3da30bbf9ffc9662b07c9f879\n",
            "Successfully built word2number\n",
            "Installing collected packages: word2number\n",
            "Successfully installed word2number-1.1\n",
            "Collecting pycontractions\n",
            "  Using cached pycontractions-2.0.1-py3-none-any.whl (9.6 kB)\n",
            "Collecting language-check>=1.0\n",
            "  Using cached language-check-1.1.tar.gz (33 kB)\n",
            "Requirement already satisfied: gensim>=2.0 in /usr/local/lib/python3.7/dist-packages (from pycontractions) (3.6.0)\n",
            "Requirement already satisfied: pyemd>=0.4.4 in /usr/local/lib/python3.7/dist-packages (from pycontractions) (0.5.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=2.0->pycontractions) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim>=2.0->pycontractions) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=2.0->pycontractions) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim>=2.0->pycontractions) (1.15.0)\n",
            "Building wheels for collected packages: language-check\n",
            "  Building wheel for language-check (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for language-check\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for language-check\n",
            "Failed to build language-check\n",
            "Installing collected packages: language-check, pycontractions\n",
            "    Running setup.py install for language-check ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-axfs5anj/language-check_993260a9da504af18e6f7dbb565af019/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-axfs5anj/language-check_993260a9da504af18e6f7dbb565af019/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-tdhdxbty/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/language-check Check the logs for full command output.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9L98pYKDpCb"
      },
      "source": [
        "#Data processing librairies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#Data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import datetime as dt\n",
        "import pickle\n",
        "from scipy.stats import chi2_contingency\n",
        "import dateparser\n",
        "from dateutil.parser import parse\n",
        "import spacy\n",
        "import re\n",
        "import string\n",
        "#import unidecode\n",
        "#NLP data processing\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from langdetect import detect\n",
        "import gensim.downloader as api\n",
        "#from pycontractions import Contractions\n",
        "#wordcloud\n",
        "#from word2number import w2n\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import bar_chart_race as bcr\n",
        "% matplotlib inline\n",
        "#Data modeling\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeClassifier,LogisticRegression\n",
        "from sklearn.ensemble import  RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
        "from sklearn.tree import  DecisionTreeClassifier\n",
        "from sklearn.neighbors import  KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import time \n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import plot_roc_curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSoqIUXzMz82",
        "outputId": "ba0318da-c5d4-42d6-f5eb-ce59d34f2a1b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbb9Fs1KcQNX"
      },
      "source": [
        "job=pd.read_csv('job.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_1iHVuvy8rX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "5c0d4556-826e-4e37-d96f-8fb9b3ff6d6c"
      },
      "source": [
        "job.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>Titre du poste</th>\n",
              "      <th>Compagnie</th>\n",
              "      <th>Domaine</th>\n",
              "      <th>Spécialité</th>\n",
              "      <th>Date publication</th>\n",
              "      <th>Date limite</th>\n",
              "      <th>Pays</th>\n",
              "      <th>Ville</th>\n",
              "      <th>Zone</th>\n",
              "      <th>Durée</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>Consultant (e)</td>\n",
              "      <td>Fonds des Nations Unies pour la Population</td>\n",
              "      <td>Management/Gestion, Finance, Comptabilité et C...</td>\n",
              "      <td>Management/Gestion</td>\n",
              "      <td>22 Juin 2008</td>\n",
              "      <td>30 Juin 2008</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Indeterminé</td>\n",
              "      <td>Introduction\\nLe Fonds des Nations Unies pour ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>EXTENDED TERM CONSULTANT</td>\n",
              "      <td>World Bank</td>\n",
              "      <td>Management/Gestion, Finance, Comptabilité et C...</td>\n",
              "      <td>Gestion de Projets</td>\n",
              "      <td>25 Juin 2008</td>\n",
              "      <td>30 Juin 2008</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Indeterminé</td>\n",
              "      <td>Introduction\\nSpecific Objectives of Consultan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>Mécanicien(ne) Automobile d’expérience</td>\n",
              "      <td>Ambassade du Canada</td>\n",
              "      <td>Mécanique</td>\n",
              "      <td>Mécanique Auto - Diesel</td>\n",
              "      <td>1 Juil 2008</td>\n",
              "      <td>4 Juil 2008</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Indéterminé</td>\n",
              "      <td>Introduction\\nAVIS DE RECRUTEMENT\\n\\r\\nLa sect...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>Consultant en Communication</td>\n",
              "      <td>PSF-CI</td>\n",
              "      <td>Communication et Journalisme</td>\n",
              "      <td>Communication</td>\n",
              "      <td>1 Juil 2008</td>\n",
              "      <td>4 Juil 2008</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Artibonite</td>\n",
              "      <td>1 mois</td>\n",
              "      <td>Introduction\\nPSF-CI (ONG) dans le cadre de so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Postes à pourvoir: \\n\\nIntroduction\\n\\n\\nFonct...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                            content\n",
              "0           0  ...  Introduction\\nLe Fonds des Nations Unies pour ...\n",
              "1           1  ...  Introduction\\nSpecific Objectives of Consultan...\n",
              "2           2  ...  Introduction\\nAVIS DE RECRUTEMENT\\n\\r\\nLa sect...\n",
              "3           3  ...  Introduction\\nPSF-CI (ONG) dans le cadre de so...\n",
              "4           4  ...  Postes à pourvoir: \\n\\nIntroduction\\n\\n\\nFonct...\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecA0QDX1VKoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28104da5-a4ec-4cda-d0ee-66dac050c14f"
      },
      "source": [
        "print(f\"Shape: \\n{job.shape}\\n\")\n",
        "print(f\"Variables infos: \\n{job.info()}\\n\")\n",
        "print(f\"Number of unique modalities: \\n{job.nunique()}\\n\")\n",
        "print(f\"Data view: \\n{job.head()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: \n",
            "(8760, 13)\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8760 entries, 0 to 8759\n",
            "Data columns (total 13 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   Unnamed: 0        8760 non-null   int64 \n",
            " 1   id                8760 non-null   int64 \n",
            " 2   Titre du poste    7862 non-null   object\n",
            " 3   Compagnie         7862 non-null   object\n",
            " 4   Domaine           7861 non-null   object\n",
            " 5   Spécialité        7602 non-null   object\n",
            " 6   Date publication  8760 non-null   object\n",
            " 7   Date limite       8760 non-null   object\n",
            " 8   Pays              7862 non-null   object\n",
            " 9   Ville             4316 non-null   object\n",
            " 10  Zone              6531 non-null   object\n",
            " 11  Durée             7849 non-null   object\n",
            " 12  content           8760 non-null   object\n",
            "dtypes: int64(2), object(11)\n",
            "memory usage: 889.8+ KB\n",
            "Variables infos: \n",
            "None\n",
            "\n",
            "Number of unique modalities: \n",
            "Unnamed: 0           227\n",
            "id                  8679\n",
            "Titre du poste      6515\n",
            "Compagnie            657\n",
            "Domaine               28\n",
            "Spécialité           150\n",
            "Date publication    2316\n",
            "Date limite         2669\n",
            "Pays                   6\n",
            "Ville                 91\n",
            "Zone                2256\n",
            "Durée               1143\n",
            "content             7749\n",
            "dtype: int64\n",
            "\n",
            "Data view: \n",
            "   Unnamed: 0  ...                                            content\n",
            "0           0  ...  Introduction\\nLe Fonds des Nations Unies pour ...\n",
            "1           1  ...  Introduction\\nSpecific Objectives of Consultan...\n",
            "2           2  ...  Introduction\\nAVIS DE RECRUTEMENT\\n\\r\\nLa sect...\n",
            "3           3  ...  Introduction\\nPSF-CI (ONG) dans le cadre de so...\n",
            "4           4  ...  Postes à pourvoir: \\n\\nIntroduction\\n\\n\\nFonct...\n",
            "\n",
            "[5 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg32bdR5E9x3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f98f715e-e098-4e6f-97e1-2c8e2ed6953f"
      },
      "source": [
        "job.isnull().any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0          False\n",
              "id                  False\n",
              "Titre du poste       True\n",
              "Compagnie            True\n",
              "Domaine              True\n",
              "Spécialité           True\n",
              "Date publication    False\n",
              "Date limite         False\n",
              "Pays                 True\n",
              "Ville                True\n",
              "Zone                 True\n",
              "Durée                True\n",
              "content             False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9BqNe4MF6UX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc30d35-c65e-4259-b671-0ee68b18d780"
      },
      "source": [
        "job.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0             0\n",
              "id                     0\n",
              "Titre du poste       898\n",
              "Compagnie            898\n",
              "Domaine              899\n",
              "Spécialité          1158\n",
              "Date publication       0\n",
              "Date limite            0\n",
              "Pays                 898\n",
              "Ville               4444\n",
              "Zone                2229\n",
              "Durée                911\n",
              "content                0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_ZlXFj_qafA"
      },
      "source": [
        "filter =job['Compagnie'].isna()\n",
        "job =job.loc[~filter,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J75y6nfvIoSl"
      },
      "source": [
        "filter1 =job['Zone'].isna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpMr-ZwiIy9d"
      },
      "source": [
        "job = job.loc[~filter1,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7ptg22cqPqt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "ab61d045-91ab-478f-d57b-893cceffc846"
      },
      "source": [
        "job.isna()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>Titre du poste</th>\n",
              "      <th>Compagnie</th>\n",
              "      <th>Domaine</th>\n",
              "      <th>Spécialité</th>\n",
              "      <th>Date publication</th>\n",
              "      <th>Date limite</th>\n",
              "      <th>Pays</th>\n",
              "      <th>Ville</th>\n",
              "      <th>Zone</th>\n",
              "      <th>Durée</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8750</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8751</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8756</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8758</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8759</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6531 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0     id  Titre du poste  ...   Zone  Durée  content\n",
              "3          False  False           False  ...  False  False    False\n",
              "11         False  False           False  ...  False  False    False\n",
              "12         False  False           False  ...  False  False    False\n",
              "14         False  False           False  ...  False  False    False\n",
              "17         False  False           False  ...  False  False    False\n",
              "...          ...    ...             ...  ...    ...    ...      ...\n",
              "8750       False  False           False  ...  False  False    False\n",
              "8751       False  False           False  ...  False  False    False\n",
              "8756       False  False           False  ...  False  False    False\n",
              "8758       False  False           False  ...  False  False    False\n",
              "8759       False  False           False  ...  False  False    False\n",
              "\n",
              "[6531 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRE4p0Qt0ob5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "6a223b66-4d20-4981-b2d3-beaa6f94d962"
      },
      "source": [
        "job.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6531.000000</td>\n",
              "      <td>6531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>100.196295</td>\n",
              "      <td>6386.951768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>58.535630</td>\n",
              "      <td>3607.769445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>50.000000</td>\n",
              "      <td>3429.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>6175.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>9341.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>226.000000</td>\n",
              "      <td>13039.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0            id\n",
              "count  6531.000000   6531.000000\n",
              "mean    100.196295   6386.951768\n",
              "std      58.535630   3607.769445\n",
              "min       0.000000     14.000000\n",
              "25%      50.000000   3429.500000\n",
              "50%     100.000000   6175.000000\n",
              "75%     150.000000   9341.500000\n",
              "max     226.000000  13039.000000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFVFhnvQtY1d"
      },
      "source": [
        "job.rename(columns ={'Titre du poste':'Job Title','Compagnie':'Company','Domaine':'Area','Spécialité':'Specialization','Date publication':'Date of Publication','Date limite':'Deadline','Pays':'Country','Durée':'Period','Ville':'City'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7juJG0G9tb_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd07eb85-826f-4774-f47b-cb340d29efef"
      },
      "source": [
        "job.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6531, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVgm2BN9djt9"
      },
      "source": [
        "job.drop_duplicates(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAdGQ9WpdVgm"
      },
      "source": [
        "job =job.drop(['Unnamed: 0'], axis= 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXkJfsYNLAOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d84a298d-f537-464e-bcd9-2e8b3f8e31bc"
      },
      "source": [
        "job.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6531, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ydA68mM9Hn4"
      },
      "source": [
        "job = job[~job['Job Title'].isna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4C0OHx_LKYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2513b97-3de3-4522-cb87-733534f53158"
      },
      "source": [
        "job.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6531, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwk2vn6Tm61v"
      },
      "source": [
        "def is_date(string, fuzzy=False):\n",
        "    \"\"\"\n",
        "    Return whether the string can be interpreted as a date.\n",
        "\n",
        "    :param string: str, string to check for date\n",
        "    :param fuzzy: bool, ignore unknown tokens in string if True\n",
        "    \"\"\"\n",
        "    try: \n",
        "        parse(string, fuzzy=fuzzy)\n",
        "        return True\n",
        "\n",
        "    except ValueError:\n",
        "        return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxp6-uRht8vr"
      },
      "source": [
        "def data_converter(my_string):\n",
        "  try:\n",
        "    return dateparser.parse(my_string).date()\n",
        "  except:\n",
        "    return  dateparser.parse('1 jan 2020').date()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J_oTyK9wcwq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "6eab8ab5-80e1-4469-829d-d35c4793adc6"
      },
      "source": [
        "job.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Job Title</th>\n",
              "      <th>Company</th>\n",
              "      <th>Area</th>\n",
              "      <th>Specialization</th>\n",
              "      <th>Date of Publication</th>\n",
              "      <th>Deadline</th>\n",
              "      <th>Country</th>\n",
              "      <th>City</th>\n",
              "      <th>Zone</th>\n",
              "      <th>Period</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>Consultant en Communication</td>\n",
              "      <td>PSF-CI</td>\n",
              "      <td>Communication et Journalisme</td>\n",
              "      <td>Communication</td>\n",
              "      <td>1 Juil 2008</td>\n",
              "      <td>4 Juil 2008</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Artibonite</td>\n",
              "      <td>1 mois</td>\n",
              "      <td>Introduction\\nPSF-CI (ONG) dans le cadre de so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>24</td>\n",
              "      <td>UN(E) CHEF DE PROJET</td>\n",
              "      <td>Centre d'Animation Paysanne et d'Action Commun...</td>\n",
              "      <td>Agriculture – Agroalimentaire</td>\n",
              "      <td>Agronomie</td>\n",
              "      <td>6 Aout 2008</td>\n",
              "      <td>20 Aout 2008</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Artibonite,Haiti</td>\n",
              "      <td>determinée</td>\n",
              "      <td>Introduction\\nONG locale cherche pour emploi i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>33</td>\n",
              "      <td>Analyste Programmeur</td>\n",
              "      <td>Les Centres Gheskio</td>\n",
              "      <td>Sciences Informatiques</td>\n",
              "      <td>Base de données</td>\n",
              "      <td>9 Aout 2008</td>\n",
              "      <td>30 Aout 2008</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Port-au-Prince</td>\n",
              "      <td>Indeterminé</td>\n",
              "      <td>Introduction\\nONG basée à Port-au-Prince désir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>35</td>\n",
              "      <td>Human Resources Manager</td>\n",
              "      <td>ong</td>\n",
              "      <td>Management/Gestion, Finance, Comptabilité et C...</td>\n",
              "      <td>Gestion des Ressources Humaines</td>\n",
              "      <td>11 Aout 2008</td>\n",
              "      <td>22 Aout 2008</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PAP</td>\n",
              "      <td>Indeterminée</td>\n",
              "      <td>Introduction\\nNon Governmental Organization is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>39</td>\n",
              "      <td>Relais dans les facultés publiques et privées</td>\n",
              "      <td>JobPaw</td>\n",
              "      <td>Communication et Journalisme</td>\n",
              "      <td>Communication</td>\n",
              "      <td>22 Aout 2008</td>\n",
              "      <td>1 Jan 2008</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Port-au-Prince</td>\n",
              "      <td>Indeterminé</td>\n",
              "      <td>Postes à pourvoir:  \\r\\n\\t\\t\\t\\t 15           ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  ...                                            content\n",
              "3   14  ...  Introduction\\nPSF-CI (ONG) dans le cadre de so...\n",
              "11  24  ...  Introduction\\nONG locale cherche pour emploi i...\n",
              "12  33  ...  Introduction\\nONG basée à Port-au-Prince désir...\n",
              "14  35  ...  Introduction\\nNon Governmental Organization is...\n",
              "17  39  ...  Postes à pourvoir:  \\r\\n\\t\\t\\t\\t 15           ...\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-wz2RmAUdTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "523f4d26-594c-4aab-f154-322f7c863ac4"
      },
      "source": [
        "job[\"Period\"].nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1037"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTcwEbsue9yb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c2c45f-8be1-4bc1-b3f5-02f3a60cb875"
      },
      "source": [
        "job[\"Job Title\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Consultant en Communication', 'UN(E) CHEF DE PROJET',\n",
              "       'Analyste Programmeur', ...,\n",
              "       'Ingénieur  Responsable des Infrastructures Hydro agricoles',\n",
              "       \"Spécialiste national en Surveillance et en  Gestion de l'Information\",\n",
              "       'Coordonnateur de préparation et réponse aux urgences'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_3SEds_sPoo"
      },
      "source": [
        "job['City']= job['City'].fillna('Undetermined')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuFqlr-msWhi"
      },
      "source": [
        "job['Zone']= job['Zone'].fillna('Undetermined')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6CQUw6Ju14C"
      },
      "source": [
        "job['Deadline'] =pd.to_datetime(job['Deadline'].apply(data_converter))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMGTmxhfzcjq"
      },
      "source": [
        "job['Date of Publication'] =pd.to_datetime(job['Date of Publication'].apply(data_converter))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4BTTrQ8M7x-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "c1d2f409-b267-46a5-e940-7a74e43c83c2"
      },
      "source": [
        "job.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Job Title</th>\n",
              "      <th>Company</th>\n",
              "      <th>Area</th>\n",
              "      <th>Specialization</th>\n",
              "      <th>Date of Publication</th>\n",
              "      <th>Deadline</th>\n",
              "      <th>Country</th>\n",
              "      <th>City</th>\n",
              "      <th>Zone</th>\n",
              "      <th>Period</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>Consultant en Communication</td>\n",
              "      <td>PSF-CI</td>\n",
              "      <td>Communication et Journalisme</td>\n",
              "      <td>Communication</td>\n",
              "      <td>2008-07-01</td>\n",
              "      <td>2008-07-04</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>Undetermined</td>\n",
              "      <td>Artibonite</td>\n",
              "      <td>1 mois</td>\n",
              "      <td>Introduction\\nPSF-CI (ONG) dans le cadre de so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>24</td>\n",
              "      <td>UN(E) CHEF DE PROJET</td>\n",
              "      <td>Centre d'Animation Paysanne et d'Action Commun...</td>\n",
              "      <td>Agriculture – Agroalimentaire</td>\n",
              "      <td>Agronomie</td>\n",
              "      <td>2008-08-06</td>\n",
              "      <td>2008-08-20</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>Undetermined</td>\n",
              "      <td>Artibonite,Haiti</td>\n",
              "      <td>determinée</td>\n",
              "      <td>Introduction\\nONG locale cherche pour emploi i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>33</td>\n",
              "      <td>Analyste Programmeur</td>\n",
              "      <td>Les Centres Gheskio</td>\n",
              "      <td>Sciences Informatiques</td>\n",
              "      <td>Base de données</td>\n",
              "      <td>2008-08-09</td>\n",
              "      <td>2008-08-30</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>Undetermined</td>\n",
              "      <td>Port-au-Prince</td>\n",
              "      <td>Indeterminé</td>\n",
              "      <td>Introduction\\nONG basée à Port-au-Prince désir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>35</td>\n",
              "      <td>Human Resources Manager</td>\n",
              "      <td>ong</td>\n",
              "      <td>Management/Gestion, Finance, Comptabilité et C...</td>\n",
              "      <td>Gestion des Ressources Humaines</td>\n",
              "      <td>2008-08-11</td>\n",
              "      <td>2008-08-22</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>Undetermined</td>\n",
              "      <td>PAP</td>\n",
              "      <td>Indeterminée</td>\n",
              "      <td>Introduction\\nNon Governmental Organization is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>39</td>\n",
              "      <td>Relais dans les facultés publiques et privées</td>\n",
              "      <td>JobPaw</td>\n",
              "      <td>Communication et Journalisme</td>\n",
              "      <td>Communication</td>\n",
              "      <td>2008-08-22</td>\n",
              "      <td>2008-01-01</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>Undetermined</td>\n",
              "      <td>Port-au-Prince</td>\n",
              "      <td>Indeterminé</td>\n",
              "      <td>Postes à pourvoir:  \\r\\n\\t\\t\\t\\t 15           ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  ...                                            content\n",
              "3   14  ...  Introduction\\nPSF-CI (ONG) dans le cadre de so...\n",
              "11  24  ...  Introduction\\nONG locale cherche pour emploi i...\n",
              "12  33  ...  Introduction\\nONG basée à Port-au-Prince désir...\n",
              "14  35  ...  Introduction\\nNon Governmental Organization is...\n",
              "17  39  ...  Postes à pourvoir:  \\r\\n\\t\\t\\t\\t 15           ...\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ywxLmHxtCU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4053bbc-5694-4ba6-895d-8adf79317b01"
      },
      "source": [
        "job.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6531 entries, 3 to 8759\n",
            "Data columns (total 12 columns):\n",
            " #   Column               Non-Null Count  Dtype         \n",
            "---  ------               --------------  -----         \n",
            " 0   id                   6531 non-null   int64         \n",
            " 1   Job Title            6531 non-null   object        \n",
            " 2   Company              6531 non-null   object        \n",
            " 3   Area                 6531 non-null   object        \n",
            " 4   Specialization       6299 non-null   object        \n",
            " 5   Date of Publication  6531 non-null   datetime64[ns]\n",
            " 6   Deadline             6531 non-null   datetime64[ns]\n",
            " 7   Country              6531 non-null   object        \n",
            " 8   City                 6531 non-null   object        \n",
            " 9   Zone                 6531 non-null   object        \n",
            " 10  Period               6519 non-null   object        \n",
            " 11  content              6531 non-null   object        \n",
            "dtypes: datetime64[ns](2), int64(1), object(9)\n",
            "memory usage: 663.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT1iW2s4yl-D"
      },
      "source": [
        "#Create season columns \n",
        "var = (job['Deadline'].dt.month*100 + job['Deadline'].dt.day - 320)%1300\n",
        "\n",
        "job['season'] = pd.cut(var, [0, 300, 602, 900, 1300], \n",
        "                      labels=['spring', 'summer', 'autumn', 'winter'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rp9F862NUB1"
      },
      "source": [
        "var= (job['Date of Publication'].dt.month*100 + job['Date of Publication'].dt.day - 320)%1300\n",
        "\n",
        "job['season'] = pd.cut(var, [0, 300, 602, 900, 1300], \n",
        "                      labels=['spring', 'summer', 'autumn', 'winter'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VeULYK250Qx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e7d18e7-5df3-4387-d44a-132005238f07"
      },
      "source": [
        "#Created date month year month_name and week columns\n",
        "job[\"month\"] = job[\"Date of Publication\"].dt.month\n",
        "job[\"year\"] = job[\"Date of Publication\"].dt.year\n",
        "job[\"week\"] = job[\"Date of Publication\"].dt.week\n",
        "job[\"month_name\"] = job[\"Date of Publication\"].dt.month_name()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS6zGAfQxTv-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "0f73e6d9-a592-4b37-9589-f79bcb8238db"
      },
      "source": [
        "job.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Job Title</th>\n",
              "      <th>Company</th>\n",
              "      <th>Area</th>\n",
              "      <th>Specialization</th>\n",
              "      <th>Date of Publication</th>\n",
              "      <th>Deadline</th>\n",
              "      <th>Country</th>\n",
              "      <th>City</th>\n",
              "      <th>Zone</th>\n",
              "      <th>Period</th>\n",
              "      <th>content</th>\n",
              "      <th>season</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>week</th>\n",
              "      <th>month_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>Consultant en Communication</td>\n",
              "      <td>PSF-CI</td>\n",
              "      <td>Communication et Journalisme</td>\n",
              "      <td>Communication</td>\n",
              "      <td>2008-07-01</td>\n",
              "      <td>2008-07-04</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>Undetermined</td>\n",
              "      <td>Artibonite</td>\n",
              "      <td>1 mois</td>\n",
              "      <td>Introduction\\nPSF-CI (ONG) dans le cadre de so...</td>\n",
              "      <td>summer</td>\n",
              "      <td>7</td>\n",
              "      <td>2008</td>\n",
              "      <td>27</td>\n",
              "      <td>July</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>24</td>\n",
              "      <td>UN(E) CHEF DE PROJET</td>\n",
              "      <td>Centre d'Animation Paysanne et d'Action Commun...</td>\n",
              "      <td>Agriculture – Agroalimentaire</td>\n",
              "      <td>Agronomie</td>\n",
              "      <td>2008-08-06</td>\n",
              "      <td>2008-08-20</td>\n",
              "      <td>Haiti</td>\n",
              "      <td>Undetermined</td>\n",
              "      <td>Artibonite,Haiti</td>\n",
              "      <td>determinée</td>\n",
              "      <td>Introduction\\nONG locale cherche pour emploi i...</td>\n",
              "      <td>summer</td>\n",
              "      <td>8</td>\n",
              "      <td>2008</td>\n",
              "      <td>32</td>\n",
              "      <td>August</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id                    Job Title  ... week month_name\n",
              "3   14  Consultant en Communication  ...   27       July\n",
              "11  24         UN(E) CHEF DE PROJET  ...   32     August\n",
              "\n",
              "[2 rows x 17 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB74jWFCMRXK"
      },
      "source": [
        "#Apply langdetect, NLP processing\n",
        "lang = detect(\"Ein, zwei, drei, vier\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlE9LLz6MRfu"
      },
      "source": [
        "job['language'] = job['content'].apply(detect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1ZvU60OuMF-"
      },
      "source": [
        "#job['language']= job['Job Title'].apply(detect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yCfhNLOmNg5"
      },
      "source": [
        "job_en = job[job.language =='en']\n",
        "job_fr = job[job.language =='fr']\n",
        "job_en.reset_index(inplace=True)\n",
        "job_fr.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AYgLxOvMa0c"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words_fr =set(stopwords.words('french'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iomfs-FRMRw1"
      },
      "source": [
        "def remove_email(x):\n",
        "  x = re.sub(r'\\S*@\\S*\\s?','',x)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzrkJpDnNEqK"
      },
      "source": [
        "def remove_ponctuation(x):\n",
        "   x = re.sub(r'[^\\w\\s]','',x)\n",
        "   return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDyI0JERNEtp"
      },
      "source": [
        "def remove_digit(x):\n",
        "  x = re.sub(r'\\d','',x)\n",
        "  return x "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FSl9QrONExL"
      },
      "source": [
        "def remove_extraline(x):\n",
        "  x = re.sub(r'\\r|\\n|\\r\\n','',x)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhYXKrWpNE0o"
      },
      "source": [
        "def remove_url(x):\n",
        "  x = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', x)\n",
        "  x = re.sub(r'^www?.\\/\\/.*[\\r\\n]*', '', x)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvOHRPyzNdmg"
      },
      "source": [
        "def remove_stopwords_fr(x):\n",
        "  my_list = word_tokenize(x)\n",
        "  my_list =[ x for x in my_list if x not in stop_words_fr]\n",
        "  return  \" \".join(my_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4br4ghlmjtW"
      },
      "source": [
        "def remove_stopwords_en(x):\n",
        "  my_list = word_tokenize(x)\n",
        "  my_list =[ x for x in my_list if x not in stop_words]\n",
        "  return  \" \".join(my_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX_R8p2iaSqF"
      },
      "source": [
        "\n",
        "def use_lemmentizer_fr(x):\n",
        "  model = spacy.load('fr_core_news_md')\n",
        "  words = model(x)\n",
        "  x = [word.lemma_ for word in words]\n",
        "  x = \" \".join(x)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KPb49wRoYSo"
      },
      "source": [
        "def use_lemmentizer_en(x):\n",
        "  model = spacy.load('en_core_web_sm')\n",
        "  words = model(x)\n",
        "  x = [word.lemma_ for word in words]\n",
        "  x = \" \".join(x)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jDdr0kmntTZ"
      },
      "source": [
        "#use_lemmentizer_fr(\"la vie est belle elle est fantastique\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2txS5kmJP_Oh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e47776f-bfa4-4690-d4c1-c85f22971ffa"
      },
      "source": [
        "job_en.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1799, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04e-KmZ5NSs9"
      },
      "source": [
        "def normalize_document_fr(x):\n",
        "  x =remove_ponctuation(x)\n",
        "  x = remove_email(x)\n",
        "  x = remove_digit(x)\n",
        "  x =remove_extraline(x)\n",
        "  x =remove_url(x)\n",
        "  x = use_lemmentizer_fr(x)\n",
        "  x = remove_stopwords_fr(x)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s97PqccZYDx2"
      },
      "source": [
        "def normalize_document_en(x):\n",
        "  x =remove_ponctuation(x)\n",
        "  x = remove_email(x)\n",
        "  x = remove_digit(x)\n",
        "  x =remove_extraline(x)\n",
        "  x =remove_url(x)\n",
        "  x = use_lemmentizer_en(x)\n",
        "  x = remove_stopwords_en(x)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg01kT5RQJ9B"
      },
      "source": [
        "import multiprocessing\n",
        "import concurrent.futures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kdSDgtBSIfX"
      },
      "source": [
        "def generate_segment(start=0,stop=1000,step=500):\n",
        "  low = start\n",
        "  segments =[]\n",
        "  for high in np.arange(start =start+step,stop=stop,step=step):\n",
        "    segments.append((low,high))\n",
        "    low=high\n",
        "  if segments[-1][1]<stop:\n",
        "    segments.append((segments[-1][1],stop))\n",
        "  return segments\n",
        "\n",
        "\n",
        "segments = generate_segment(start=0,stop=job_en.shape[0],step=100)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrdKsV3TbVQ6",
        "outputId": "a1bf4d68-6ec4-4d1b-ebd4-6f9303b08afe"
      },
      "source": [
        "generate_segment(start=0,stop=1000,step=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 10),\n",
              " (10, 20),\n",
              " (20, 30),\n",
              " (30, 40),\n",
              " (40, 50),\n",
              " (50, 60),\n",
              " (60, 70),\n",
              " (70, 80),\n",
              " (80, 90),\n",
              " (90, 100),\n",
              " (100, 110),\n",
              " (110, 120),\n",
              " (120, 130),\n",
              " (130, 140),\n",
              " (140, 150),\n",
              " (150, 160),\n",
              " (160, 170),\n",
              " (170, 180),\n",
              " (180, 190),\n",
              " (190, 200),\n",
              " (200, 210),\n",
              " (210, 220),\n",
              " (220, 230),\n",
              " (230, 240),\n",
              " (240, 250),\n",
              " (250, 260),\n",
              " (260, 270),\n",
              " (270, 280),\n",
              " (280, 290),\n",
              " (290, 300),\n",
              " (300, 310),\n",
              " (310, 320),\n",
              " (320, 330),\n",
              " (330, 340),\n",
              " (340, 350),\n",
              " (350, 360),\n",
              " (360, 370),\n",
              " (370, 380),\n",
              " (380, 390),\n",
              " (390, 400),\n",
              " (400, 410),\n",
              " (410, 420),\n",
              " (420, 430),\n",
              " (430, 440),\n",
              " (440, 450),\n",
              " (450, 460),\n",
              " (460, 470),\n",
              " (470, 480),\n",
              " (480, 490),\n",
              " (490, 500),\n",
              " (500, 510),\n",
              " (510, 520),\n",
              " (520, 530),\n",
              " (530, 540),\n",
              " (540, 550),\n",
              " (550, 560),\n",
              " (560, 570),\n",
              " (570, 580),\n",
              " (580, 590),\n",
              " (590, 600),\n",
              " (600, 610),\n",
              " (610, 620),\n",
              " (620, 630),\n",
              " (630, 640),\n",
              " (640, 650),\n",
              " (650, 660),\n",
              " (660, 670),\n",
              " (670, 680),\n",
              " (680, 690),\n",
              " (690, 700),\n",
              " (700, 710),\n",
              " (710, 720),\n",
              " (720, 730),\n",
              " (730, 740),\n",
              " (740, 750),\n",
              " (750, 760),\n",
              " (760, 770),\n",
              " (770, 780),\n",
              " (780, 790),\n",
              " (790, 800),\n",
              " (800, 810),\n",
              " (810, 820),\n",
              " (820, 830),\n",
              " (830, 840),\n",
              " (840, 850),\n",
              " (850, 860),\n",
              " (860, 870),\n",
              " (870, 880),\n",
              " (880, 890),\n",
              " (890, 900),\n",
              " (900, 910),\n",
              " (910, 920),\n",
              " (920, 930),\n",
              " (930, 940),\n",
              " (940, 950),\n",
              " (950, 960),\n",
              " (960, 970),\n",
              " (970, 980),\n",
              " (980, 990),\n",
              " (990, 1000)]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ykyw1dbaFIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb2de42c-6d29-454b-f10e-f5f88d4785cf"
      },
      "source": [
        " job_en.loc[0:5,'content'] = job_en.loc[0:5,'content'].apply(normalize_document_en)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEXo1_oYge-A",
        "outputId": "621c0cdc-d6af-4e7e-e5ca-8207e4baf507"
      },
      "source": [
        "job_fr.loc[0:5,'content'] = job_fr.loc[0:5,'content'].apply(normalize_document_fr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hVa8Ih_fbok"
      },
      "source": [
        "#job_en.to_excel(\"job_en.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuVLO7XYVcbg"
      },
      "source": [
        "def job_normalize_document_en(start=0,stop=1801):\n",
        "  job_en.loc[start:stop,'content'] = job_en.loc[start:stop,'content'].apply(normalize_document_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPjCWCrmdTcz",
        "outputId": "28300ecc-7f13-41a4-a5f0-f25be75d76b2"
      },
      "source": [
        "job_fr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4712, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lKVV8LIdarP",
        "outputId": "ddb7964e-380c-4fdd-e85a-9154f0d86e33"
      },
      "source": [
        "job_en.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1799, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dry1zPRQb3Jx"
      },
      "source": [
        "job_en.content = job_en.content.apply(normalize_document_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHnFYvULlXtD"
      },
      "source": [
        "job_fr.content = job_fr.content.apply(normalize_document_fr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aYoaHQlCynM"
      },
      "source": [
        "job_fr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBeFCEVjkCz8"
      },
      "source": [
        "job_en.to_excel(\"Last_job_en.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGTbrxd4kp6u"
      },
      "source": [
        "job_last_en = pd.read_excel(\"Last_job_en.xlsx\")\n",
        "job_last_en.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVStrp1CYnlK"
      },
      "source": [
        "def job_normalize_document_fr(start=0,stop=1801):\n",
        "  job_fr.loc[start:stop,'content'] = job_fr.loc[start:stop,'content'].apply(normalize_document_fr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRN4XvqUU5eJ"
      },
      "source": [
        "segments = generate_segment(start=0,stop=job_en.shape[0],step =3)\n",
        "processes =[]\n",
        "for segment in segments:\n",
        "  p1 = multiprocessing.Process(target=job_normalize_document_en,args=[segment[0],segment[1]])\n",
        "  p1.start()\n",
        "  processes.append(p1)\n",
        "\n",
        "for p2 in processes:\n",
        "  p2.join()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1U4UwTdQF-k"
      },
      "source": [
        "job_en.to_excel(\"job_en.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbcoWrxu2aBV"
      },
      "source": [
        "job_en.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCFJ1vfWQSaO"
      },
      "source": [
        "segments = generate_segment(start=0,stop=job_en.shape[0],step =2)\n",
        "processes =[]\n",
        "for segment in segments:\n",
        "  p1 = multiprocessing.Process(target=job_normalize_document_fr,args=[segment[0],segment[1]])\n",
        "  p1.start()\n",
        "  processes.append(p1)\n",
        "\n",
        "for p2 in processes:\n",
        "  p2.join()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qElqLGHN4vU_"
      },
      "source": [
        "!pip install xlsxwriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQljn1Si46W8"
      },
      "source": [
        "job_fr.to_excel(\"job_fr.xlsx\", engine='xlsxwriter')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGtG1A6AZDlA"
      },
      "source": [
        "job_fr.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp0APo8wSEFa"
      },
      "source": [
        "#job_en['content'] = job['content'].apply(normalize_document_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v5VNmcl8XiG"
      },
      "source": [
        "#job_en['Job Title']= job_en['Job Title'].apply(normalize_document_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ9KLZgFCATj"
      },
      "source": [
        "normalize_document_fr(job_fr['content'].values[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYNHSm8GcxoB"
      },
      "source": [
        "job_en['content'][500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1VIlCIzNSwM"
      },
      "source": [
        "normalize_document_en(job_en.content.values[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F70D2f52-u3U"
      },
      "source": [
        "#job_en.to_csv(\"job_en.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb6t9biz8VnF"
      },
      "source": [
        "job_en=pd.read_csv('job_en.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73lkODsZRcnk"
      },
      "source": [
        "job_en=pd.read_excel('job_en.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuNkX3zAca6X"
      },
      "source": [
        "job_fr = pd.read_excel('job_fr.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv6kr__vrFbW"
      },
      "source": [
        "#job_fr['content'] = job['content'].apply(normalize_document_fr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1bgPsaSUrZo"
      },
      "source": [
        "job_en =job_en.drop(['Unnamed: 0'], axis= 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AloAJBIMO6D2"
      },
      "source": [
        "job_en.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxw47PwWNotJ"
      },
      "source": [
        "job_en.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTnkcWKl5oh2"
      },
      "source": [
        "job_en['Job Title']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSxSP5DMCizj"
      },
      "source": [
        "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
        "labels = 'Job Title', 'Specialization', 'Area'\n",
        "sizes = [15, 30, 45]\n",
        "explode = (0, 0.1, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5eYzdYFL6Er"
      },
      "source": [
        "# Data Analysis\n",
        "Explore the dataset to discover relationships between records or columns and patterns within the data.\n",
        "\n",
        "## Descriptive Statistical Analysis\n",
        "Using basic statistical measures such as measurements of central tendancy such as mean, median and mode.\n",
        "\n",
        "### Distribution of Variables\n",
        "Identify the distribution of the data to understand the range of values and how the data is structured.\n",
        "\n",
        "### Outliers in the dataset\n",
        "Identify if there are any outliers in the dataset based on statistical measures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvAErC42bdVg"
      },
      "source": [
        "Nombres job en moyenne par mois"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzccD4CzF9KT"
      },
      "source": [
        "#Distribution par moyenne\n",
        "job_month_year =job_en.groupby(by=['year','month']).size().to_frame()\n",
        "job_month_year.columns = ['Total job']\n",
        "job_month_year.reset_index(inplace=True)\n",
        "job_month_year.groupby(by=['month'])['Total job'].mean().to_frame().reset_index().sort_values(by=\"Total job\",inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEEuJUBK-Fk6"
      },
      "source": [
        "job_month_year"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL94YlSjyurI"
      },
      "source": [
        "data_map =pd.pivot_table(data=job_en,index=[\"month\",\"month_name\"],columns ='year',values='id',aggfunc=\"count\",fill_value=0).astype('int')\n",
        "data_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLJUuTCf0aKz"
      },
      "source": [
        "#Distribution des Jobs en fonction du mois et de l'annee\n",
        "fig,axes =plt.subplots(figsize=(12, 10))\n",
        "sns.heatmap(data=data_map,annot=True, fmt=\"d\", cmap=\"YlOrRd\", linewidths=.6,ax=axes)\n",
        "axes.set_title(\"Job distribution per month and year on average\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6ph13_KLtWu"
      },
      "source": [
        "job.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFo649hsLIF5"
      },
      "source": [
        "data_map1 =pd.pivot_table(data=job_en,index=\"Area\",values='id',columns='year',aggfunc=\"count\",fill_value=0).astype('int')\n",
        "data_map1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjcXs6oSMPsF"
      },
      "source": [
        "#Evolution des Jobs en fonction de l'annee\n",
        "fig,axes =plt.subplots(figsize=(12, 10))\n",
        "sns.heatmap(data=data_map1,annot=True, fmt=\"d\", cmap=\"YlOrRd\", linewidths=.6,ax=axes)\n",
        "axes.set_title(\"Job distribution per month and year\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLWOnGFK95LO"
      },
      "source": [
        "#Totals Jobs par mois\n",
        "job_month_year =job_en.groupby(by=['year','month']).size().to_frame()\n",
        "job_month_year.columns = ['Total job']\n",
        "job_month_year.reset_index(inplace=True)\n",
        "job_month_year.groupby(by=['month'])['Total job'].mean().to_frame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWPvzyVsI6Xr"
      },
      "source": [
        "#Calculer jobs par season et par mois\n",
        "print('Jobs per season and per month')\n",
        "data_mp5 =pd.pivot_table(data=job_en,columns=[\"season\"],index ='year',values='id',aggfunc=\"count\",fill_value=0).astype('int')\n",
        "data_mp5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVR2Ycn-wJ0Z"
      },
      "source": [
        "group=job_en.groupby(by=\"Area\").mean().round()\n",
        "group"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynsCtyu0o-y5"
      },
      "source": [
        "#Evolution des Jobs par season\n",
        "fig,axes =plt.subplots(figsize=(8, 4))\n",
        "sns.barplot(data=data_mp5)\n",
        "axes.set_title(\"Job distribution per month and season\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElSNIwcNlAgK"
      },
      "source": [
        "data_map2 =pd.pivot_table(data=job_en,index=\"year\",values='id',columns='Specialization',aggfunc=\"count\",fill_value=0).astype('int')\n",
        "data_map2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvVKQq7qauaW"
      },
      "source": [
        "#Barchart pour montrer l'evolution des Specialite en fonction de l'annee\n",
        "bcr.bar_chart_race(df=data_map2, title='Evolution of specialization',n_bars=20, orientation='h', fixed_order= False, cmap='prism', steps_per_period=50,period_length=2000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFlPxbMfsp83"
      },
      "source": [
        "def generate_barchart(data=job_en, title =\"\",abs_value =\"Total\",rel_value=\"Percent\",figsize =(10,6),horizontal=True):\n",
        "  plt.figure(figsize=figsize)\n",
        "  if horizontal:\n",
        "      axes = sns.barplot(data=data,x=abs_value,y=data.index,palette='Blues')\n",
        "      i=0\n",
        "      for tot, perc in zip(data[abs_value],data[rel_value]):\n",
        "        axes.text(tot/2,\n",
        "                  i,\n",
        "                  str(np.round(perc*100,2))+ \"%\",\n",
        "                    fontdict=dict(color='blue',fontsize=12,horizontalalignment=\"center\")\n",
        "                  )\n",
        "        axes.text(tot+3,\n",
        "                  i,\n",
        "                  str(tot),\n",
        "                    fontdict=dict(color='blue',fontsize=12,horizontalalignment=\"center\")\n",
        "                  )\n",
        "        \n",
        "        i+=1\n",
        "      plt.title(title)\n",
        "      plt.show()\n",
        "  else:\n",
        "        axes = sns.barplot(data=data,y=abs_value,x=data.index)\n",
        "        i=0\n",
        "        for tot, perc in zip(data[abs_value],data[rel_value]):\n",
        "          axes.text(i,\n",
        "                    tot/2,\n",
        "                    str(np.round(perc*100,2))+ \"%\",\n",
        "                      fontdict=dict(color='Yelow',fontsize=12,horizontalalignment=\"center\")\n",
        "                    )\n",
        "          axes.text(i,\n",
        "                    tot+3,\n",
        "                    str(tot),\n",
        "                      fontdict=dict(color='green',fontsize=12,horizontalalignment=\"center\")\n",
        "                    )\n",
        "          \n",
        "          i+=1\n",
        "        plt.title(title)\n",
        "        plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVkl0hads6qo"
      },
      "source": [
        "def prob_category(data,top_n =6,col=\"Pclass_letter\", abs_value =\"Total\",rel_value =\"Percent\",show_plot=False, title=\"\",figsize=(10,20),horizontal=True):\n",
        " \n",
        "   res1 = data[col].value_counts().to_frame()\n",
        "   res1.columns = [abs_value]\n",
        "\n",
        "   res2 = data[col].value_counts(normalize=True).to_frame()\n",
        "   res2.columns = [rel_value]\n",
        "   if  not show_plot:\n",
        "     return pd.concat([res1,res2],axis=1).head(top_n)\n",
        "   else:\n",
        "     job_en = pd.concat([res1,res2],axis=1).head(top_n)\n",
        "     generate_barchart(data=job_en, title =title,abs_value =abs_value,rel_value=rel_value,figsize =figsize,horizontal=horizontal)\n",
        "     return job_en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO6mVUeXkSYv"
      },
      "source": [
        "#Calcule des totals et pourcentages \"Company, Job Title, Specialization, Areas, City\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUmWBJu9tEM9"
      },
      "source": [
        "prob_category(data=job, top_n= 5, col='Company', show_plot=True, figsize= (10,4),title='Top 10 Company and Percents')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-NLVa8FtVSc"
      },
      "source": [
        "prob_category(data=job, top_n= 5, col='Specialization', show_plot=True, figsize= (8,4),title='Top 5 Specializations')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_fvi1RYtjTA"
      },
      "source": [
        "prob_category(data=job, top_n= 5, col='Area', show_plot=True, figsize= (6,4),title='Top 5 Areas')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK2CBRMXtl8v"
      },
      "source": [
        "prob_category(data=job, top_n= 10, col='Job Title', show_plot=True, figsize= (10,4),title='Top 10 Jobs en english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQQS-4LOPkZ9"
      },
      "source": [
        "prob_category(data=job_fr, top_n= 10, col='Job Title', show_plot=True, figsize= (10,4),title='Top 10 Jobs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq7BYgWSwX-s"
      },
      "source": [
        "prob_category(data=job, top_n= 5, col='City', show_plot=True, figsize= (5,4),title='Top 5 City')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_h6t05eWoTp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33WH4KAnKU1R"
      },
      "source": [
        "comment_words = ''\n",
        "stopwords = set(STOPWORDS)\n",
        " \n",
        "for val in job_en['Job Title']:\n",
        "    val = str(val)\n",
        "    tokens = val.split()\n",
        "    for i in range(len(tokens)):\n",
        "        tokens[i] = tokens[i].lower()\n",
        "     \n",
        "    comment_words += \" \".join(tokens)+\" \"\n",
        " \n",
        "wordcloud = WordCloud(width = 800, height = 800,\n",
        "                background_color ='white',\n",
        "                stopwords = stopwords,\n",
        "                min_font_size = 10).generate(comment_words)\n",
        "                      \n",
        "plt.figure(figsize = (5, 5), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        " \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEFULcNKUC-P"
      },
      "source": [
        "comment_words = ''\n",
        "stopwords = set(STOPWORDS)\n",
        " \n",
        "for val in job_fr['Job Title']:\n",
        "    val = str(val)\n",
        "    tokens = val.split()\n",
        "    for i in range(len(tokens)):\n",
        "        tokens[i] = tokens[i].lower()\n",
        "     \n",
        "    comment_words += \" \".join(tokens)+\" \"\n",
        " \n",
        "wordcloud = WordCloud(width = 800, height = 800,\n",
        "                background_color ='white',\n",
        "                stopwords = stopwords,\n",
        "                min_font_size = 10).generate(comment_words)\n",
        "                      \n",
        "plt.figure(figsize = (5, 5), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        " \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIU1GktxQ_ON"
      },
      "source": [
        "#Classement des categories de specialite par Job titre\n",
        "job1 =job_en.groupby(by=['Category_Spec'])['Job Title'].count().to_frame()\n",
        "job1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bawhHnoB_T6Y"
      },
      "source": [
        "prob_category(data=job_en, top_n= 10, col='Category_Spec', show_plot=True, figsize= (8,4),title='Categories of Specialization')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPJ8vSuyW0YG"
      },
      "source": [
        "job_en = pd.read_excel(\"job_en.xlsx\")\n",
        "job_fr = pd.read_excel(\"job_fr.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XBii8rMXFlE"
      },
      "source": [
        "job = pd.concat([job_en,job_fr],axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDO3Ex8ZXVGR"
      },
      "source": [
        "job.drop(columns=['Unnamed: 0',\t'index'],inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj7p73ShXqwX"
      },
      "source": [
        "job_en.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOmYFPNLVZj1"
      },
      "source": [
        "#Create variable and check model\n",
        "tfidfVectorizer = TfidfVectorizer(ngram_range=(0,1))\n",
        "X_train_counts_tfidf = tfidfVectorizer.fit_transform(job_en.content.values)\n",
        "df_final =pd.DataFrame(X_train_counts_tfidf.toarray(),columns=tfidfVectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQFahfKxVo5L"
      },
      "source": [
        "df_final['class'] = job_en['Category_Spec']\n",
        "df_final =df_final.dropna(how='any')\n",
        "df_final.loc[df_final['class'] == 'Sciences Humaines et Sociales','class'] = 'Class 1'\n",
        "df_final.loc[df_final['class']!= 'Class 1','class'] = 'Class 2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD2Icn2VVuVE"
      },
      "source": [
        "df_final['class'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrnCeD0TVuJ5"
      },
      "source": [
        "X=df_final.drop(columns=['class'])\n",
        "y =df_final[['class']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUfQB4DaVt8p"
      },
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size =0.3,random_state=49)\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upAG9vxaV3oF"
      },
      "source": [
        "clf.fit(X_train,y_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgoPuiE9V3jS"
      },
      "source": [
        "clf.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q1hm2JTWDhC"
      },
      "source": [
        "rd =RandomForestClassifier()\n",
        "rd.fit(X_train,y_train)\n",
        "rd.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bxl-0vaWDcw"
      },
      "source": [
        "#Check other model\n",
        "times_list = []\n",
        "scores = []\n",
        "model_names = [\"LogisticRegression\",\"RidgeClassifier\",\"AdaBoostClassifier\",\"GradientBoostingClassifier\",\"RandomForestClassifier\",\"DecisionTreeClassifier\",\"KNeighborsClassifier\"]\n",
        "models = [LogisticRegression(),RidgeClassifier(),AdaBoostClassifier(),GradientBoostingClassifier(),RandomForestClassifier(),DecisionTreeClassifier(),KNeighborsClassifier()]\n",
        "for model in models:\n",
        "  start = time.time()\n",
        "  model.fit(X_train,y_train)\n",
        "  end = time.time()\n",
        "  times_list.append(end-start)\n",
        "  scores.append( model.score(X_test,y_test))\n",
        "  plot_confusion_matrix(model,X_test,y_test)\n",
        "  plot_roc_curve(model,X_test,y_test)\n",
        "\n",
        "df = pd.DataFrame(dict(names=model_names,scores=scores,times=times_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEdwWGA9WlgX"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeGF1WvL-pk5"
      },
      "source": [
        "#Training the model\n",
        "rc = RidgeClassifier()\n",
        "print(rc)\n",
        "\n",
        "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
        "                max_iter=None, normalize=True, random_state=None, solver='auto',\n",
        "                tol=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrX9DOSJJAaX"
      },
      "source": [
        "rc.fit(X_train, y_train)\n",
        "score = rc.score(X_train, y_train)\n",
        "print(\"Score: \", score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHBzULg9J4p_"
      },
      "source": [
        "#Predicting and accuracy check\n",
        "y_pred = rc.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZvTOylXKFS9"
      },
      "source": [
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heVyeoGBN7V5"
      },
      "source": [
        "plot_confusion_matrix(rc,X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqmT-DI4KHxn"
      },
      "source": [
        "cr = classification_report(y_test, y_pred)\n",
        "print(cr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPYRmMY2vEbW"
      },
      "source": [
        "texts = job_en['Job Title'].values[0]\n",
        "\n",
        "# Create and generate a word cloud image:\n",
        "wordcloud = WordCloud().generate(texts)\n",
        "# Display the generated image:\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LgIQZi3iUJB"
      },
      "source": [
        "text = \" \".join(review for review in job.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUywflAl9L3W"
      },
      "source": [
        "# Reflections\n",
        "## Summary of Data Analysis\n",
        "- What insights should the user takeaway from EDA.\n",
        "\n",
        "## Questions unanswered\n",
        "- What aspects of the research question were we unable to answer and why?\n",
        "\n",
        "## Recommendations\n",
        "- What should the reader do next with this information?\n",
        "\n",
        "## Next Steps\n",
        "- What will the analyst do next based on the analysis?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YCsV1HSIAgJ"
      },
      "source": [
        "#### Summary of Data Analysis\n",
        "\n",
        "#####-Before doing the analysis we first cleaned up our dataset. We used Natural Language Processing to help us filter them. For the BE we have:\n",
        "#####-The total average number of jobs per month. All months are significant, \n",
        "#####especially November and March. as well as all years but from 2010.\n",
        "#####-We also have the total of the domains per year. In the last years, the highest field is management, finance, accounting and trade, they also become much higher from 2010. As well as medical professionals, humanities and social sciences.\n",
        "#####-We still have the total per season. There is not too much evolution but the fall and winter unlike summer are much higher.\n",
        "#####We have a bar chart that shows the evolution of the specialties by year. Management remains higher then accounting and project management.\n",
        "#####-Then the top 10 domains, specialties, city, jobs and company are quite explicit.\n",
        "#####-With the specialization category ranking. We noticed that the highest specializations are humanities and social sciences, natural sciences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsJ1rIBhI6P1"
      },
      "source": [
        "#### Questions unanswered\n",
        "\n",
        "#####The aspects of the research question that we were not able to answer are the following: \n",
        "#####What are the most used, most demanded work tools in the labor market? Languages and communications? The work experience required of the candidates and their level of education?\n",
        "#####We can't answer them because of the lack of data, as the ones we have managed to Webscaper don't have these variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_NWMG9ZKOBb"
      },
      "source": [
        "\n",
        "#### Recommendations\n",
        "\n",
        "#####*   In terms of orientation, young people could be interested in the following areas: Management, Finance, Accounting, and Health Professionals.in specialties based on humanities and social sciences, natural sciences. It should be noted that after a natural event or a disaster the offers are much higher and come mainly from private companies.\n",
        "*   \n",
        "*   \n",
        "*  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iNMt4ERKRpv"
      },
      "source": [
        "#### Next Steps\n",
        "\n",
        "#####The analysis here is not complete, we still have to continue the Natural Language Processing for more clarity in the data and then make a Word Cloud for job titles to finally generate other insights . And finally, to make a Power BI."
      ]
    }
  ]
}